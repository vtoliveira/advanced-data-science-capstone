{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Science Capstone - Week 3 - Model Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will select our classifier algorithm that it is best fitted for our problem, that is, classifying tweets between three different classes, such as positive, negative and neutral.\n",
    "\n",
    "For that, it is well established that three algorithms have higher performance for text classification, to list: Naive Bayes, Support Vector Machines and Random Forests. Therefore, they will be tested against our constructed dataset, we will also apply evaluation for this dataset, cross-validation for hyperparameter tuning and to finish, discuss some difficulties to this specific task and intuitions and how we can proceed to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model definition we have chosen to do hyperparameter and some feature extraction in this phase such as Bag of Words, TF-IDF Vectors, Count Vectores, etc. Since they also are included on the cross-validation tasks for a variety of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14132, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data_preprocessed.csv\", sep='\\t')\n",
    "\n",
    "# checking its dimensions\n",
    "data.dropna(subset=['text_stemming'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>...</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>positive_emoticon</th>\n",
       "      <th>negative_emoticon</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>text_stemming</th>\n",
       "      <th>negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what said .</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>said</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>plus you've added commercials to the experienc...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>plu ad commerci experi tacki</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i didn't today must mean i need to take anothe...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>today must mean need take anoth trip exclam</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it's really aggressive to blast obnoxious \" en...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.142</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>realli aggress blast obnoxi entertain guest fa...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>and it's a really big bad thing about it</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5829</td>\n",
       "      <td>realli big bad thing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "     ...                  user_timezone positive_emoticon negative_emoticon  \\\n",
       "0    ...     Eastern Time (US & Canada)                 0                 0   \n",
       "1    ...     Pacific Time (US & Canada)                 0                 0   \n",
       "2    ...     Central Time (US & Canada)                 0                 0   \n",
       "3    ...     Pacific Time (US & Canada)                 0                 0   \n",
       "4    ...     Pacific Time (US & Canada)                 0                 0   \n",
       "\n",
       "                                   text_preprocessed neg_scores  neu_scores  \\\n",
       "0                                        what said .      0.000       1.000   \n",
       "1  plus you've added commercials to the experienc...      0.000       1.000   \n",
       "2  i didn't today must mean i need to take anothe...      0.000       1.000   \n",
       "3  it's really aggressive to blast obnoxious \" en...      0.248       0.609   \n",
       "4           and it's a really big bad thing about it      0.351       0.649   \n",
       "\n",
       "   pos_scores compound_scores  \\\n",
       "0       0.000          0.0000   \n",
       "1       0.000          0.0000   \n",
       "2       0.000          0.0000   \n",
       "3       0.142         -0.2716   \n",
       "4       0.000         -0.5829   \n",
       "\n",
       "                                       text_stemming  negation  \n",
       "0                                               said     False  \n",
       "1                       plu ad commerci experi tacki     False  \n",
       "2        today must mean need take anoth trip exclam      True  \n",
       "3  realli aggress blast obnoxi entertain guest fa...     False  \n",
       "4                               realli big bad thing     False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14132, 6), (14132, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['text_stemming', 'neu_scores', 'neg_scores', 'compound_scores', 'negation', 'pos_scores']\n",
    "label = ['airline_sentiment']\n",
    "\n",
    "data['negation'] = pd.get_dummies(data.negation)\n",
    "\n",
    "\n",
    "X = data[[col for col in data.columns if col in features]]\n",
    "y = data[label]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are (9892, 6) and (4240, 6)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print(\"Shapes are {} and {}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing with our classification process, it is fundamental in any machine learning project to check our baseline, that is, what is the majority class of our dataset. In this way, we must perform above this threshold, and this is called baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.641832\n",
       "neutral     0.209159\n",
       "positive    0.149009\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train.values.ravel()).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our classifier with two types of text processors, tfidf and countVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "\n",
    "tfidf = Pipeline([\n",
    "                ('selector', TextSelector(key='text_stemming')),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "            ])\n",
    "\n",
    "countvect = Pipeline([\n",
    "                ('selector', TextSelector(key='text_stemming')),\n",
    "                ('countvect', CountVectorizer())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "negation =  Pipeline([\n",
    "                ('selector', NumberSelector(key='negation')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "neu_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neu_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "neg_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neg_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "pos_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='pos_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "\n",
    "compound_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='compound_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# defining different sets of text processors\n",
    "\n",
    "def features_union(textProcessor):\n",
    "    return FeatureUnion([('text', textProcessor), \n",
    "                      ('negation', negation),\n",
    "                      ('neu_scores', neu_scores),\n",
    "                      ('neg_scores', neg_scores),\n",
    "                      ('pos_scores', pos_scores),\n",
    "                      ('compound_scores', compound_scores)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9892, 6), (4240, 6))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(y_train.values.ravel())\n",
    "\n",
    "y_train = le.transform(y_train.values.ravel())\n",
    "y_test = le.transform(y_test.values.ravel())\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77900943396226419"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "features_count = features_union(countvect)\n",
    "nb_pipeline = Pipeline([('features', features_count),\n",
    "                       ('nb', clf)])\n",
    "\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "nb_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79481132075471694"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "features_tfidf = features_union(tfidf)\n",
    "svm_pipeline = Pipeline([('features', features_tfidf),\n",
    "                       ('svm', svm)])\n",
    "\n",
    "\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "svm_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79268867924528297"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf_pipeline = Pipeline([('features', features_count),\n",
    "                       ('rf', rf)])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76438679245283014"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation for Naive Bayes Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features_tfidf = features_union(tfidf)\n",
    "\n",
    "nb_pipeline = Pipeline([('feats', features_tfidf),  ('clf', MultinomialNB())])\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'feats__text__tfidf__binary':(False, True),\n",
    "    'feats__text__tfidf__binary':('l1', 'l2', None),\n",
    "    'clf__alpha': (1.0, 5.0, 10.0),\n",
    "    'clf__fit_prior': (True, False),                               \n",
    "}\n",
    "\n",
    "nb_gs = GridSearchCV(nb_pipeline, parameters, cv=3)\n",
    "nb_gs.fit(X_train, y_train)\n",
    "nb_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Best params: {}'.format(nb_gs.best_params_))\n",
    "nb_cv_results = pd.DataFrame(nb_gs.cv_results_)\n",
    "nb_cv_results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81014150943396224"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation for SVM Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features_count = features_union(tfidf)\n",
    "svm_count_pipeline = Pipeline([('feats', features_count),  ('clf', LinearSVC())])\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'clf__loss': ('hinge', 'squared_hinge'),\n",
    "    'clf__C': (0.1, 0.5, 0.6, 1, 4, 5, 10, 100),\n",
    "    'clf__class_weight': (None, 'balanced')                                    \n",
    "}\n",
    "\n",
    "svm_gs = GridSearchCV(svm_count_pipeline, parameters, cv=3)\n",
    "svm_gs.fit(X_train, y_train)\n",
    "svm_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 0.5, 'clf__class_weight': 'balanced', 'clf__loss': 'squared_hinge', 'feats__text__tfidf__max_df': 0.5, 'feats__text__tfidf__ngram_range': (1, 2), 'feats__text__tfidf__use_idf': True}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__loss</th>\n",
       "      <th>param_feats__text__tfidf__max_df</th>\n",
       "      <th>param_feats__text__tfidf__ngram_range</th>\n",
       "      <th>param_feats__text__tfidf__use_idf</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737034</td>\n",
       "      <td>0.744842</td>\n",
       "      <td>0.743833</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>451</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.758302</td>\n",
       "      <td>0.758945</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.135401</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.058834</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733091</td>\n",
       "      <td>0.739078</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>475</td>\n",
       "      <td>0.751251</td>\n",
       "      <td>0.754966</td>\n",
       "      <td>0.755761</td>\n",
       "      <td>0.753993</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363443</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.742415</td>\n",
       "      <td>0.739486</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>484</td>\n",
       "      <td>0.748369</td>\n",
       "      <td>0.752843</td>\n",
       "      <td>0.751668</td>\n",
       "      <td>0.750960</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
       "0       0.143589      0.004203         0.050598        0.005267          0.1   \n",
       "1       0.135401      0.007359         0.058834        0.013769          0.1   \n",
       "2       0.363443      0.032684         0.062494        0.000015          0.1   \n",
       "\n",
       "  param_clf__class_weight param_clf__loss param_feats__text__tfidf__max_df  \\\n",
       "0                    None           hinge                              0.5   \n",
       "1                    None           hinge                              0.5   \n",
       "2                    None           hinge                              0.5   \n",
       "\n",
       "  param_feats__text__tfidf__ngram_range param_feats__text__tfidf__use_idf  \\\n",
       "0                                (1, 1)                             False   \n",
       "1                                (1, 1)                              True   \n",
       "2                                (1, 2)                             False   \n",
       "\n",
       "        ...        split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0       ...                 0.737034           0.744842         0.743833   \n",
       "1       ...                 0.733091           0.739078         0.739891   \n",
       "2       ...                 0.732484           0.742415         0.739486   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.005189              451            0.753223            0.758302   \n",
       "1        0.005911              475            0.751251            0.754966   \n",
       "2        0.004973              484            0.748369            0.752843   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.758945          0.756823         0.002559  \n",
       "1            0.755761          0.753993         0.001965  \n",
       "2            0.751668          0.750960         0.001894  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Best params: {}'.format(svm_gs.best_params_))\n",
    "svm_cv_results = pd.DataFrame(svm_gs.cv_results_)\n",
    "svm_cv_results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation for RF Classifier\n",
    "features_count = features_union(tfidf)\n",
    "rf_pipeline_cv = Pipeline([('feats', features_count),  ('rf', RandomForestClassifier())])\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2)),\n",
    "    'rf__max_features': (0.5, 0.7, 1.0),\n",
    "    'rf__bootstrap': (False ,True),\n",
    "    'rf__class_weight': ('balanced', 'balanced_subsample', None),\n",
    "    'rf__n_estimators':(10, 50, 80)\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf_pipeline_cv, parameters, cv=3)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "rf_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(100, 150)\n",
      "  (lstm): LSTM(150, 128, num_layers=3, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models import SentimentRNN\n",
    "\n",
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = 100\n",
    "output_size = 3\n",
    "embedding_dim = 150\n",
    "hidden_dim = 128\n",
    "n_layers = 3\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
