{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Science Capstone - Week 2 - Feature Engineering/Creation and ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook differs from the Feature Cration (Bag of Words) because we will preprocess and save data considering word embedding approaches. I found it easier to do in a different notebook. Consider this one as a compliment for the one named *Feature Creation (Bag of  Words) - Twitter US Airline Sentiment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14133, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/data_preprocessed.csv\", sep='\\t')\n",
    "\n",
    "# checking its dimensions\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "data['text_preprocessed'] = data.text.apply(lambda x: utils.preprocess_tweet(x, punctuation = True))\n",
    "data['text_preprocessed'] = data.text_preprocessed.apply(lambda x: utils.preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "We will create word embeddings using the library called gensim. It is easy to implement and hyper parameters tuning. An important concept here is that before preprocessing we need to split data between train and test set. Because if we apply word embeddings for all data, it will leakage information to test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9893,), (4240,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data['text_preprocessed']\n",
    "y = data['airline_sentiment']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, y_train, y_test = train_test_split(text, y, test_size=0.30, random_state=0)\n",
    "\n",
    "text_train.shape, text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(text_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from gensim.models import word2vec\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parameters\n",
    "num_features = 25    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 5         # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"word_embeddings/25features_1minwords_5context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9893\n",
      "['ive', 'literally', 'been', 'holding', 'for', 'more', 'than', '2', 'hours', 'now', '<PERIOD>', 'i', 'was', 'told', '2hrs', '<PERIOD>', 'you', 'all', 'are', 'sabotaging', 'any', 'chance', 'i', 'have', 'of', 'getting', 'home']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('las-den', 0.839499831199646),\n",
       " ('no-enertainment-on', 0.8384756445884705),\n",
       " ('swift', 0.8367525339126587),\n",
       " ('display', 0.8246525526046753),\n",
       " ('989', 0.8217084407806396),\n",
       " ('5350', 0.8195247650146484),\n",
       " ('19-', 0.81806480884552),\n",
       " ('sfo-jfk', 0.8122883439064026),\n",
       " ('delayed-no', 0.812042772769928),\n",
       " ('compounding', 0.8109996914863586)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('electrical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12958    [in, miami, and, the, agents, rachel, wong, an...\n",
       "13610    [delivered, mom's, delayed, bag, to, the, wron...\n",
       "4523     [u, were, bae, until, u, lost, both, of, my, b...\n",
       "Name: text_preprocessed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
